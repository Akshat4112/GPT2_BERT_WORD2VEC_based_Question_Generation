{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install spacy\n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "import _pickle as cPickle\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpPickle(fileName, content):\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "def loadPickle(fileName):    \n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def pickleExists(fileName):\n",
    "    file = Path(fileName)\n",
    "    \n",
    "    if file.is_file():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract answers and the sentence they are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAnswers(qas, doc):\n",
    "    answers = []\n",
    "\n",
    "    senStart = 0\n",
    "    senId = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        senLen = len(sentence.text)\n",
    "\n",
    "        for answer in qas:\n",
    "            answerStart = answer['answers'][0]['answer_start']\n",
    "\n",
    "            if (answerStart >= senStart and answerStart < (senStart + senLen)):\n",
    "                answers.append({'sentenceId': senId, 'text': answer['answers'][0]['text']})\n",
    "\n",
    "        senStart += senLen\n",
    "        senId += 1\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - Clean answers from stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenIsAnswer(token, sentenceId, answers):\n",
    "    for i in range(len(answers)):\n",
    "        if (answers[i]['sentenceId'] == sentenceId):\n",
    "            if (answers[i]['text'] == token):\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save named entities start points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNEStartIndexs(doc):\n",
    "    neStarts = {}\n",
    "    for ne in doc.ents:\n",
    "        neStarts[ne.start] = ne\n",
    "        \n",
    "    return neStarts \n",
    "\n",
    "def getSentenceStartIndexes(doc):\n",
    "    senStarts = []\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        senStarts.append(sentence[0].i)\n",
    "    \n",
    "    return senStarts\n",
    "    \n",
    "def getSentenceForWordPosition(wordPos, senStarts):\n",
    "    for i in range(1, len(senStarts)):\n",
    "        if (wordPos < senStarts[i]):\n",
    "            return i - 1\n",
    "        \n",
    "def addWordsForParagrapgh(newWords, text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    neStarts = getNEStartIndexs(doc)\n",
    "    senStarts = getSentenceStartIndexes(doc)\n",
    "    \n",
    "    #index of word in spacy doc text\n",
    "    i = 0\n",
    "    \n",
    "    while (i < len(doc)):\n",
    "        #If the token is a start of a Named Entity, add it and push to index to end of the NE\n",
    "        if (i in neStarts):\n",
    "            word = neStarts[i]\n",
    "            #add word\n",
    "            currentSentence = getSentenceForWordPosition(word.start, senStarts)\n",
    "            wordLen = word.end - word.start\n",
    "            shape = ''\n",
    "            for wordIndex in range(word.start, word.end):\n",
    "                shape += (' ' + doc[wordIndex].shape_)\n",
    "\n",
    "            newWords.append([word.text,\n",
    "                            0,\n",
    "                            0,\n",
    "                            currentSentence,\n",
    "                            wordLen,\n",
    "                            word.label_,\n",
    "                            None,\n",
    "                            None,\n",
    "                            None,\n",
    "                            shape])\n",
    "            i = neStarts[i].end - 1\n",
    "        #If not a NE, add the word if it's not a stopword or a non-alpha (not regular letters)\n",
    "        else:\n",
    "            if (doc[i].is_stop == False and doc[i].is_alpha == True):\n",
    "                word = doc[i]\n",
    "\n",
    "                currentSentence = getSentenceForWordPosition(i, senStarts)\n",
    "                wordLen = 1\n",
    "\n",
    "                newWords.append([word.text,\n",
    "                                0,\n",
    "                                0,\n",
    "                                currentSentence,\n",
    "                                wordLen,\n",
    "                                None,\n",
    "                                word.pos_,\n",
    "                                word.tag_,\n",
    "                                word.dep_,\n",
    "                                word.shape_])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df):\n",
    "    columnsToEncode = ['NER', 'POS', \"TAG\", 'DEP']\n",
    "\n",
    "    for column in columnsToEncode:\n",
    "        one_hot = pd.get_dummies(df[column])\n",
    "        one_hot = one_hot.add_prefix(column + '_')\n",
    "\n",
    "        df = df.drop(column, axis = 1)\n",
    "        df = df.join(one_hot)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDf(text):\n",
    "    words = []\n",
    "    addWordsForParagrapgh(words, text)\n",
    "\n",
    "    wordColums = ['text', 'titleId', 'paragrapghId', 'sentenceId','wordCount', 'NER', 'POS', 'TAG', 'DEP','shape']\n",
    "    df = pd.DataFrame(words, columns=wordColums)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDf(df):\n",
    "    #One-hot encoding\n",
    "    wordsDf = oneHotEncodeColumns(df)\n",
    "\n",
    "    #Drop unused columns\n",
    "    columnsToDrop = ['text', 'titleId', 'paragrapghId', 'sentenceId', 'shape']\n",
    "    wordsDf = wordsDf.drop(columnsToDrop, axis = 1)\n",
    "\n",
    "    #Add missing colums \n",
    "    predictorColumns = ['wordCount','NER_CARDINAL','NER_DATE','NER_EVENT','NER_FAC','NER_GPE','NER_LANGUAGE','NER_LAW','NER_LOC','NER_MONEY','NER_NORP','NER_ORDINAL','NER_ORG','NER_PERCENT','NER_PERSON','NER_PRODUCT','NER_QUANTITY','NER_TIME','NER_WORK_OF_ART','POS_ADJ','POS_ADP','POS_ADV','POS_CCONJ','POS_DET','POS_INTJ','POS_NOUN','POS_NUM','POS_PART','POS_PRON','POS_PROPN','POS_PUNCT','POS_SYM','POS_VERB','POS_X','TAG_''','TAG_-LRB-','TAG_.','TAG_ADD','TAG_AFX','TAG_CC','TAG_CD','TAG_DT','TAG_EX','TAG_FW','TAG_IN','TAG_JJ','TAG_JJR','TAG_JJS','TAG_LS','TAG_MD','TAG_NFP','TAG_NN','TAG_NNP','TAG_NNPS','TAG_NNS','TAG_PDT','TAG_POS','TAG_PRP','TAG_PRP$','TAG_RB','TAG_RBR','TAG_RBS','TAG_RP','TAG_SYM','TAG_TO','TAG_UH','TAG_VB','TAG_VBD','TAG_VBG','TAG_VBN','TAG_VBP','TAG_VBZ','TAG_WDT','TAG_WP','TAG_WRB','TAG_XX','DEP_ROOT','DEP_acl','DEP_acomp','DEP_advcl','DEP_advmod','DEP_agent','DEP_amod','DEP_appos','DEP_attr','DEP_aux','DEP_auxpass','DEP_case','DEP_cc','DEP_ccomp','DEP_compound','DEP_conj','DEP_csubj','DEP_csubjpass','DEP_dative','DEP_dep','DEP_det','DEP_dobj','DEP_expl','DEP_intj','DEP_mark','DEP_meta','DEP_neg','DEP_nmod','DEP_npadvmod','DEP_nsubj','DEP_nsubjpass','DEP_nummod','DEP_oprd','DEP_parataxis','DEP_pcomp','DEP_pobj','DEP_poss','DEP_preconj','DEP_predet','DEP_prep','DEP_prt','DEP_punct','DEP_quantmod','DEP_relcl','DEP_xcomp']\n",
    "\n",
    "    for feature in predictorColumns:\n",
    "        if feature not in wordsDf.columns:\n",
    "            wordsDf[feature] = 0\n",
    "    \n",
    "    return wordsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWords(wordsDf, df):\n",
    "    \n",
    "    predictorPickleName = 'nb-predictor.pkl'\n",
    "    predictor = loadPickle(predictorPickleName)\n",
    "    \n",
    "    y_pred = predictor.predict_proba(wordsDf)\n",
    "\n",
    "    labeledAnswers = []\n",
    "    for i in range(len(y_pred)):\n",
    "        labeledAnswers.append({'word': df.iloc[i]['text'], 'prob': y_pred[i][0]})\n",
    "    \n",
    "    return labeledAnswers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blankAnswer(firstTokenIndex, lastTokenIndex, sentStart, sentEnd, doc):\n",
    "    leftPartStart = doc[sentStart].idx\n",
    "    leftPartEnd = doc[firstTokenIndex].idx\n",
    "    rightPartStart = doc[lastTokenIndex].idx + len(doc[lastTokenIndex])\n",
    "    rightPartEnd = doc[sentEnd - 1].idx + len(doc[sentEnd - 1])\n",
    "    \n",
    "    question = doc.text[leftPartStart:leftPartEnd] + '_____' + doc.text[rightPartStart:rightPartEnd]\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addQuestions(answers, text):\n",
    "    doc = nlp(text)\n",
    "    currAnswerIndex = 0\n",
    "    qaPair = []\n",
    "\n",
    "    #Check wheter each token is the next answer\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            \n",
    "            #If all the answers have been found, stop looking\n",
    "            if currAnswerIndex >= len(answers):\n",
    "                break\n",
    "            \n",
    "            #In the case where the answer is consisted of more than one token, check the following tokens as well.\n",
    "            answerDoc = nlp(answers[currAnswerIndex]['word'])\n",
    "            answerIsFound = True\n",
    "            \n",
    "            for j in range(len(answerDoc)):\n",
    "                if token.i + j >= len(doc) or doc[token.i + j].text != answerDoc[j].text:\n",
    "                    answerIsFound = False\n",
    "           \n",
    "            #If the current token is corresponding with the answer, add it \n",
    "            if answerIsFound:\n",
    "                question = blankAnswer(token.i, token.i + len(answerDoc) - 1, sent.start, sent.end, doc)\n",
    "                \n",
    "                qaPair.append({'question' : question, 'answer': answers[currAnswerIndex]['word'], 'prob': answers[currAnswerIndex]['prob']})\n",
    "                \n",
    "                currAnswerIndex += 1\n",
    "                \n",
    "    return qaPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortAnswers(qaPairs):\n",
    "    orderedQaPairs = sorted(qaPairs, key=lambda qaPair: qaPair['prob'])\n",
    "    \n",
    "    return orderedQaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.300d.txt'\n",
    "tmp_file = 'word2vec-glove.6B.300d.txt'\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors(answer, count):\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "\n",
    "    #Return count many distractors\n",
    "    distractors = list(map(lambda x: x[0], closestWords))[0:count]\n",
    "    \n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDistractors(qaPairs, count):\n",
    "    for qaPair in qaPairs:\n",
    "        distractors = generate_distractors(qaPair['answer'], count)\n",
    "        qaPair['distractors'] = distractors\n",
    "    \n",
    "    return qaPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQuestions(text, count):\n",
    "    \n",
    "    # Extract words \n",
    "    df = generateDf(text)\n",
    "    wordsDf = prepareDf(df)\n",
    "    \n",
    "    # Predict \n",
    "    labeledAnswers = predictWords(wordsDf, df)\n",
    "    \n",
    "    # Transform questions\n",
    "    qaPairs = addQuestions(labeledAnswers, text)\n",
    "    \n",
    "    # Pick the best questions\n",
    "    orderedQaPairs = sortAnswers(qaPairs)\n",
    "    \n",
    "    # Generate distractors\n",
    "    questions = addDistractors(orderedQaPairs[:count], 4)\n",
    "    \n",
    "    # Print\n",
    "    for i in range(count):\n",
    "        display(Markdown('### Question ' + str(i + 1) + ':'))\n",
    "        print(questions[i]['question'])\n",
    "\n",
    "        display(Markdown('#### Answer:'))\n",
    "        print(questions[i]['answer'])\n",
    "        \n",
    "        display(Markdown('#### Incorrect answers:'))\n",
    "        for distractor in questions[i]['distractors']:\n",
    "            print(distractor)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQuestions(text, count):\n",
    "    \n",
    "    # Extract words \n",
    "    df = generateDf(text)\n",
    "    wordsDf = prepareDf(df)\n",
    "    \n",
    "    # Predict \n",
    "    labeledAnswers = predictWords(wordsDf, df)\n",
    "    \n",
    "    # Transform questions\n",
    "    qaPairs = addQuestions(labeledAnswers, text)\n",
    "    \n",
    "    # Pick the best questions\n",
    "    orderedQaPairs = sortAnswers(qaPairs)\n",
    "    \n",
    "    # Generate distractors\n",
    "    questions = addDistractors(orderedQaPairs[:count], 4)\n",
    "    \n",
    "    # Print\n",
    "    for i in range(count):\n",
    "        display(Markdown('### Question ' + str(i + 1) + ':'))\n",
    "        print(questions[i]['question'])\n",
    "\n",
    "        display(Markdown('#### Answer:'))\n",
    "        print(questions[i]['answer'])\n",
    "        \n",
    "        display(Markdown('#### Incorrect answers:'))\n",
    "        for distractor in questions[i]['distractors']:\n",
    "            print(distractor)\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input text and call to function with 2 params\n",
    "1. text\n",
    "2. Number of questions to be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator GaussianNB from version 0.20.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 1:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their collective era was suffused with wide-ranging _____] but also marked by the declining status of women,[33] and the incorporation of untouchability into an organised system of belief.[g][34]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creativity,[32\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 2:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[29] and _____ and Jainism had arisen, proclaiming social orders unlinked to heredity.[30]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buddhism\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinduism\n",
      "taoism\n",
      "mahayana\n",
      "jainism\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 3:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern humans arrived on the _____ subcontinent from Africa no later than 55,000 years ago.[24]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indian\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india\n",
      "pakistani\n",
      "delhi\n",
      "kashmir\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 4:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the _____ river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indus\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ganges\n",
      "chenab\n",
      "sutlej\n",
      "jhelum\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 5:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest, unfolding as the language of the Rigveda, and recording the dawning of _____ in India.[27]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinduism\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buddhism\n",
      "jainism\n",
      "sikhism\n",
      "christianity\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 6:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The _____ languages of India were supplanted in the northern and western regions.[28]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dravidian\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indo-aryan\n",
      "indo-european\n",
      "tibeto-burman\n",
      "indic\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 7:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In South India, the Middle kingdoms exported _____-languages scripts and religious cultures to the kingdoms of Southeast Asia\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dravidian\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indo-aryan\n",
      "indo-european\n",
      "tibeto-burman\n",
      "indic\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 8:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, _____ only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third\n",
      "fourth\n",
      "first\n",
      "fifth\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 9:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly _____, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diverse\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varied\n",
      "disparate\n",
      "diversity\n",
      "variety\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question 10:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In _____, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South India\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Incorrect answers:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest, unfolding as the language of the Rigveda, and recording the dawning of Hinduism in India.[27] The Dravidian languages of India were supplanted in the northern and western regions.[28] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[29] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[30] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[31] Their collective era was suffused with wide-ranging creativity,[32] but also marked by the declining status of women,[33] and the incorporation of untouchability into an organised system of belief.[g][34] In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia\"\n",
    "\n",
    "generateQuestions(text, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations to be done:\n",
    "1. It supports single word variant using word2vec, this needs to be upgraded to phrase2vec\n",
    "2. Use of more specialized NER systems which find contextual entities from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
